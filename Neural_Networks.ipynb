{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network for Knowledge Graph Learning\n",
    "* [ER-MLP](#ER-MLP)\n",
    "* [Neural Tensor Network](#Neural-Tensor-Network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Common imports\n",
    "import tensorflow as tf\n",
    "from core.knowledge_graph import KnowledgeGraph\n",
    "from core.link_predict_utils import *\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "%pylab --no-import-all\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "def calc_log_eval(predicts, labels, logger, step):\n",
    "    mrr, hit_at_10, auc_pr, ap, precision, num_pos = metrics_in_a_batch(predicts, labels)\n",
    "    logger.add_summary(tf.Summary(\n",
    "        value=[tf.Summary.Value(tag='Summary/MRR', simple_value=mrr),\n",
    "               tf.Summary.Value(tag='Summary/HIT@10', simple_value=hit_at_10),\n",
    "               tf.Summary.Value(tag='Summary/AUC_PR', simple_value=auc_pr),\n",
    "               tf.Summary.Value(tag='Summary/Average_precision', simple_value=ap),\n",
    "               tf.Summary.Value(tag='Summary/Precision@0.5', simple_value=precision)]), step)\n",
    "    print(\"mmr: %f, hit@10: %f, auc_pr: %f, ap: %f, positive predicts: %d, precision: %f\" %\n",
    "          (mrr, hit_at_10, auc_pr, ap, num_pos, precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WARNING!!!!\n",
    "# Remove every file in `./tmp/` dir.\n",
    "decide = input('Remove all files in tmp/ ? (y/n)')\n",
    "\n",
    "if decide.lower() == 'y' or decide.lower() == 'yes':\n",
    "    if os.path.exists('./tmp'):\n",
    "        shutil.rmtree('./tmp/')\n",
    "    print('tmp files cleaned')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ER-MLP\n",
    "* [Build Graph](#Build-ER-Graph)\n",
    "* [Training](#ER-Training)\n",
    "* [Evaluation](#ER-Evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definitions\n",
    "import core.er_mlp_model as er_mlp_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build ER Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Graph...\n",
      "Graph is built.\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "dataset = 'data/kin'\n",
    "num_slice = 100\n",
    "rank_e = 100\n",
    "rank_r = 100\n",
    "valid_percent = 0.05\n",
    "test_percent = 0.05\n",
    "lambda_para = 0.0001\n",
    "\n",
    "# Read database\n",
    "database = KnowledgeGraph()\n",
    "database.read_data_from_txt(dataset)\n",
    "database.spilt_train_valid_test(valid_percent, test_percent)\n",
    "num_entities = database.number_of_entities()\n",
    "num_relations = database.number_of_relations()\n",
    "\n",
    "# TensorFlow Graph\n",
    "er_mlp_graph = tf.Graph()\n",
    "with er_mlp_graph.as_default():\n",
    "    with tf.name_scope('Feed_in'):\n",
    "        batch_input = tf.placeholder(shape=[None, 3], name='batch', dtype=tf.int32)\n",
    "        labels_input = tf.placeholder(shape=[None], name='labels', dtype=tf.float32)\n",
    "\n",
    "    print('Building Graph...')\n",
    "    predicts, embed_normalize, optimizer, loss, _, _, summary = er_mlp_model.build_graph(\n",
    "        batch_input, labels_input, num_entities, num_relations, rank_e, rank_r, num_slice, lambda_para)\n",
    "\n",
    "    saver = tf.train.Saver(tf.trainable_variables())\n",
    "    print('Graph is built.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession(graph=er_mlp_graph)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Parameters for training\n",
    "max_iter = 20000\n",
    "corrupt_size_train = 10\n",
    "corrupt_size_eval = 50\n",
    "batch_size = 6000\n",
    "save_per_iter = 300\n",
    "eval_per_iter = 100\n",
    "\n",
    "# Tensorflow logs\n",
    "train_writer = tf.summary.FileWriter('./tmp/log/train', er_mlp_graph)\n",
    "valid_writer = tf.summary.FileWriter('./tmp/log/valid')\n",
    "\n",
    "# Terminate condition for training\n",
    "min_loss = float('inf')\n",
    "valids_no_improve = 0\n",
    "max_valids_no_imporve = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ER Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Start training\")\n",
    "for step in range(1, max_iter + 1):\n",
    "    batch, labels = make_corrupt(database.get_train_batch(batch_size), database,\n",
    "                                 num_entities, corrupt_size_train)\n",
    "    train_summary, train_loss, _ = sess.run([summary, loss, optimizer], \n",
    "                                            feed_dict={batch_input: batch, labels_input: labels})\n",
    "    sess.run(embed_normalize)\n",
    "    train_writer.add_summary(train_summary, step)\n",
    "    print('Iter %d: Loss = %f' % (step, train_loss), end='\\r')\n",
    "    \n",
    "    if step % eval_per_iter == 0:\n",
    "        print('--------------Evaluation---------------')\n",
    "        #------ Evaluating on training set ------\n",
    "        print('Training set')\n",
    "        train_valid_set, train_valid_labels = make_corrupt(database.get_train_batch(batch_size), database,\n",
    "                                                           num_entities, corrupt_size_eval)\n",
    "        train_valid_predicts = sess.run(predicts, feed_dict={batch_input: train_valid_set})\n",
    "        calc_log_eval(train_valid_predicts, np.array(train_valid_labels), train_writer, step)\n",
    "\n",
    "        #------ Evaluating on validation set ------\n",
    "        print('Validation set')\n",
    "        valid_set, valid_labels = make_corrupt(database.get_valid_set(), database,\n",
    "                                               num_entities, corrupt_size_eval)\n",
    "        valid_summary, valid_predicts, valid_loss = sess.run([summary, predicts, loss],\n",
    "                                                             feed_dict={batch_input: valid_set,\n",
    "                                                                        labels_input: valid_labels})\n",
    "        valid_writer.add_summary(valid_summary, step)\n",
    "        calc_log_eval(valid_predicts, np.array(valid_labels), valid_writer, step)\n",
    "        print('**Validation loss = %f' % valid_loss)\n",
    "\n",
    "        if valid_loss < min_loss:\n",
    "            min_loss = valid_loss\n",
    "            valids_no_improve = 0\n",
    "        else:\n",
    "            valids_no_improve = valids_no_improve + 1\n",
    "        \n",
    "        if valids_no_improve >= max_valids_no_imporve:\n",
    "            break\n",
    "        \n",
    "    if step % save_per_iter == 0:\n",
    "        saver.save(sess, './tmp/save/er_mlp_model', global_step=step)\n",
    "        print('***Saved model at iteration %d' % step)\n",
    "print('Training done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ER Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./tmp/save/er_mlp_model-11700\n",
      "####### Test Evaluation #######\n",
      "Test loss:  0.07760059\n",
      "mmr: 0.959857, hit@10: 1.000000, auc_pr: 0.935556, ap: 0.935613, positive predicts: 663, precision: 0.752640\n"
     ]
    }
   ],
   "source": [
    "# Restore model and evaluate\n",
    "restore_step = 11700\n",
    "saver.restore(sess, './tmp/save/er_mlp_model-%d' % restore_step)\n",
    "\n",
    "print('####### Test Evaluation #######')\n",
    "test_set, test_labels = make_corrupt(database.get_test_set(), database,\n",
    "                                     num_entities, corrupt_size_eval)\n",
    "test_predicts, test_loss = sess.run([predicts, loss], feed_dict={batch_input: test_set,\n",
    "                                                                 labels_input: test_labels})\n",
    "print('Test loss: ', test_loss)\n",
    "mrr, hit_at_10, auc_pr, ap, precision, num_pos = metrics_in_a_batch(test_predicts, np.array(test_labels))\n",
    "print(\"mmr: %f, hit@10: %f, auc_pr: %f, ap: %f, positive predicts: %d, precision: %f\" %\n",
    "      (mrr, hit_at_10, auc_pr, ap, num_pos, precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Tensor Network\n",
    "* [Build Graph](#Build-NTN-Graph)\n",
    "* [Training](#NTN-Training)\n",
    "* [Evaluation](#NTN-Evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definitions\n",
    "import core.ntn_model as ntn_model\n",
    "\n",
    "def fill_feed_dict(input_list_r, data_list_r, input_list, data_list, num_relations):\n",
    "    feed_dict = {}\n",
    "    for (var, value) in zip(input_list_r, data_list_r):\n",
    "        for r in range(num_relations):\n",
    "            feed_dict[var[r]] = value[r]\n",
    "\n",
    "    for (var, value) in zip(input_list, data_list):\n",
    "        feed_dict[var] = value\n",
    "\n",
    "    return feed_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build NTN Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Graph...\n",
      "Graph built.\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "slice_size = 2\n",
    "rank = 100\n",
    "valid_percent = 0.05\n",
    "test_percent = 0.05\n",
    "lambda_para = 0.0001\n",
    "\n",
    "# Database\n",
    "dataset = 'data/kin'\n",
    "database = KnowledgeGraph()\n",
    "database.read_data_from_txt(dataset)\n",
    "database.spilt_train_valid_test(valid_percent, test_percent)\n",
    "num_entities = database.number_of_entities()\n",
    "num_relations = database.number_of_relations()\n",
    "\n",
    "# TensorFlow Graph\n",
    "ntn_graph = tf.Graph()\n",
    "with ntn_graph.as_default():\n",
    "    with tf.name_scope('Feed_in'):\n",
    "        batch_input = [tf.placeholder(shape=[None, 2], name='batch_%d' % r, dtype=tf.int32)\n",
    "                       for r in range(num_relations)]\n",
    "        r_empty_input = [tf.placeholder(shape=[], name='empty_%d' % r, dtype=tf.bool)\n",
    "                         for r in range(num_relations)]\n",
    "        labels_input = tf.placeholder(shape=[None], name='labels', dtype=tf.float32)\n",
    "    print('Building Graph...')\n",
    "    predicts, embed_normalize, optimizer, loss, _, summary = ntn_model.build_graph(\n",
    "        batch_input, labels_input, r_empty_input, num_entities,\n",
    "        num_relations, rank, slice_size, lambda_para)\n",
    "    saver = tf.train.Saver(tf.trainable_variables())\n",
    "    print('Graph built.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession(graph=ntn_graph)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Parameters for training\n",
    "batch_size = 6000\n",
    "max_iter = 20000\n",
    "corrupt_size_train = 10\n",
    "corrupt_size_eval = 100\n",
    "save_per_iter = 300\n",
    "eval_per_iter = 100\n",
    "\n",
    "# Tensorflow logs\n",
    "train_writer = tf.summary.FileWriter('./tmp/log/train', ntn_graph)\n",
    "valid_writer = tf.summary.FileWriter('./tmp/log/valid')\n",
    "\n",
    "# Terminate condition for training\n",
    "min_loss = float('inf')\n",
    "valids_no_improve = 0\n",
    "max_valids_no_imporve = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NTN Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Start training.')\n",
    "for step in range(1, max_iter + 1):\n",
    "    batch, labels = make_corrupt(database.get_train_batch(batch_size), database,\n",
    "                                 num_entities, corrupt_size_train)\n",
    "    batch_list, labels, r_empty = make_split(batch, labels, num_relations)\n",
    "    labels = np.hstack(labels)\n",
    "    feed_dict = fill_feed_dict([batch_input, r_empty_input], [batch_list, r_empty],\n",
    "                               [labels_input], [labels], num_relations)\n",
    "    train_summary, train_loss, _ = sess.run([summary, loss, optimizer], feed_dict=feed_dict)\n",
    "    sess.run(embed_normalize)\n",
    "    train_writer.add_summary(train_summary, step)\n",
    "    print('Iter %d: Loss = %f' % (step, train_loss), end='\\r')\n",
    "\n",
    "    if step % eval_per_iter == 0:\n",
    "        print('-------------Evaluation------------')\n",
    "        print('Training set')\n",
    "        train_valid_set, train_valid_labels = make_corrupt(database.get_train_batch(batch_size), database,\n",
    "                                                           num_entities, corrupt_size_eval)\n",
    "        train_valid_list, train_valid_labels, train_valid_r_empty = make_split(batch, labels, num_relations)\n",
    "        \n",
    "        feed_dict = fill_feed_dict([batch_input, r_empty_input], [train_valid_list, train_valid_r_empty],\n",
    "                                   [labels_input], [train_valid_labels], num_relations)\n",
    "        \n",
    "        train_valid_predicts = sess.run(predicts, feed_dict=feed_dict)\n",
    "        calc_log_eval(train_valid_predicts, np.array(train_valid_labels), train_writer, step)\n",
    "\n",
    "        print('Evaluating on validation set...')\n",
    "        valid_set, valid_labels = make_corrupt(database.get_valid_set(), database,\n",
    "                                               num_entities, corrupt_size_eval)\n",
    "        valid_list, valid_labels, valid_r_empty = make_split(batch, labels, num_relations)\n",
    "        \n",
    "        feed_dict = fill_feed_dict([batch_input, r_empty_input], [valid_list, valid_r_empty],\n",
    "                                   [labels_input], [valid_labels], num_relations)\n",
    "        \n",
    "        valid_summary, valid_predicts, valid_loss = sess.run([summary, predicts, loss], feed_dict=feed_dict)\n",
    "        valid_writer.add_summary(valid_summary, step)\n",
    "        calc_log_eval(valid_predicts, np.array(valid_labels), valid_writer, step)\n",
    "        print('**Validation loss = %f' % valid_loss)\n",
    "\n",
    "        if valid_loss < min_loss:\n",
    "            min_loss = valid_loss\n",
    "            valids_no_improve = 0\n",
    "        else:\n",
    "            valids_no_improve = valids_no_improve + 1\n",
    "        \n",
    "        if valids_no_improve >= max_valids_no_imporve:\n",
    "            break\n",
    "\n",
    "    if step % save_per_iter == 0:\n",
    "        saver.save(sess, './tmp/save/ntn_model', global_step=step)\n",
    "        print('***Saved model at iteration %d' % step)\n",
    "print('Training done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NTN Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./tmp/save/ntn_model-3900\n",
      "####### Test Evaluation #######\n",
      "Test loss:  0.055506162\n",
      "mmr: 0.984252, hit@10: 1.000000, auc_pr: 0.975398, ap: 0.975400, positive predicts: 5747, precision: 0.943971\n"
     ]
    }
   ],
   "source": [
    "# Restore model and evaluate\n",
    "restore_step = 3900\n",
    "saver.restore(sess, './tmp/save/ntn_model-%d' % restore_step)\n",
    "\n",
    "print('####### Test Evaluation #######')\n",
    "test_set, test_labels = make_corrupt(database.get_test_set(), database,\n",
    "                                     num_entities, corrupt_size_eval)\n",
    "test_list, test_labels, test_r_empty = make_split(batch, labels, num_relations)\n",
    "feed_dict = fill_feed_dict([batch_input, r_empty_input], [test_list, test_r_empty],\n",
    "                           [labels_input], [test_labels], num_relations)\n",
    "test_predicts, test_loss = sess.run([predicts, loss], feed_dict=feed_dict)\n",
    "\n",
    "print('Test loss: ', test_loss)\n",
    "mrr, hit_at_10, auc_pr, ap, precision, num_pos = metrics_in_a_batch(test_predicts, np.array(test_labels))\n",
    "print(\"mmr: %f, hit@10: %f, auc_pr: %f, ap: %f, positive predicts: %d, precision: %f\" %\n",
    "      (mrr, hit_at_10, auc_pr, ap, num_pos, precision))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
